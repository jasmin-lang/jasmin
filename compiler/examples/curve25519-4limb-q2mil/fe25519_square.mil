param int crypto_scalarmult_curve25519_amd64_64_38 = 38;
export fn crypto_scalarmult_curve25519_amd64_64_fe25519_square(reg u64 rp, reg u64 xp){
	 reg bool cf;
	 reg u64 r0;
	 reg u64 r1;
	 reg u64 r2;
	 reg u64 r3;
	 reg u64 squarer4;
	 reg u64 squarer5;
	 reg u64 squarer6;
	 reg u64 squarer7;
	 reg u64 squarer8;
	 reg u64 squarerax;
	 reg u64 squarerdx;
	 reg u64 squaret1;
	 reg u64 squaret2;
	 reg u64 squaret3;
	 reg u64 squarezero;

	squarer7 = #x86_MOV(0);
	squarerax = [xp + 1*8];
	squarerdx, squarerax = squarerax * [xp + 0*8];
	r1 = squarerax;
	r2 = squarerdx;
	squarerax = [xp + 2*8];
	squarerdx, squarerax = squarerax * [xp + 1*8];
	r3 = squarerax;
	squarer4 = squarerdx;
	squarerax = [xp + 3*8];
	squarerdx, squarerax = squarerax * [xp + 2*8];
	squarer5 = squarerax;
	squarer6 = squarerdx;
	squarerax = [xp + 2*8];
	squarerdx, squarerax = squarerax * [xp + 0*8];
	cf, r2 += squarerax;
	cf, r3 += squarerdx + cf;
	_, squarer4 += 0 + cf;
	squarerax = [xp + 3*8];
	squarerdx, squarerax = squarerax * [xp + 1*8];
	cf, squarer4 += squarerax;
	cf, squarer5 += squarerdx + cf;
	_, squarer6 += 0 + cf;
	squarerax = [xp + 3*8];
	squarerdx, squarerax = squarerax * [xp + 0*8];
	cf, r3 += squarerax;
	cf, squarer4 += squarerdx + cf;
	cf, squarer5 += 0 + cf;
	cf, squarer6 += 0 + cf;
	_, squarer7 += 0 + cf;
	cf, r1 += r1;
	cf, r2 += r2 + cf;
	cf, r3 += r3 + cf;
	cf, squarer4 += squarer4 + cf;
	cf, squarer5 += squarer5 + cf;
	cf, squarer6 += squarer6 + cf;
	_, squarer7 += squarer7 + cf;
	squarerax = [xp + 0*8];
	squarerdx, squarerax = squarerax * [xp + 0*8];
	r0 = squarerax;
	squaret1 = squarerdx;
	squarerax = [xp + 1*8];
	squarerdx, squarerax = squarerax * [xp + 1*8];
	squaret2 = squarerax;
	squaret3 = squarerdx;
	squarerax = [xp + 2*8];
	squarerdx, squarerax = squarerax * [xp + 2*8];
	cf, r1 += squaret1;
	cf, r2 += squaret2 + cf;
	cf, r3 += squaret3 + cf;
	cf, squarer4 += squarerax + cf;
	cf, squarer5 += squarerdx + cf;
	cf, squarer6 += 0 + cf;
	_, squarer7 += 0 + cf;
	squarerax = [xp + 3*8];
	squarerdx, squarerax = squarerax * [xp + 3*8];
	cf, squarer6 += squarerax;
	_, squarer7 += squarerdx + cf;
	squarerax = squarer4;
	squarerdx, squarerax = squarerax * crypto_scalarmult_curve25519_amd64_64_38;
	squarer4 = squarerax;
	squarerax = squarer5;
	squarer5 = squarerdx;
	squarerdx, squarerax = squarerax * crypto_scalarmult_curve25519_amd64_64_38;
	cf, squarer5 += squarerax;
	squarerax = squarer6;
	squarer6 = #x86_MOV(0);
	_, squarer6 += squarerdx + cf;
	squarerdx, squarerax = squarerax * crypto_scalarmult_curve25519_amd64_64_38;
	cf, squarer6 += squarerax;
	squarerax = squarer7;
	squarer7 = #x86_MOV(0);
	_, squarer7 += squarerdx + cf;
	squarerdx, squarerax = squarerax * crypto_scalarmult_curve25519_amd64_64_38;
	cf, squarer7 += squarerax;
	squarer8 = #x86_MOV(0);
	_, squarer8 += squarerdx + cf;
	cf, r0 += squarer4;
	cf, r1 += squarer5 + cf;
	cf, r2 += squarer6 + cf;
	cf, r3 += squarer7 + cf;
	squarezero = #x86_MOV(0);
	_, squarer8 += squarezero + cf;
	squarer8 *= 38;
	cf, r0 += squarer8;
	cf, r1 += squarezero + cf;
	cf, r2 += squarezero + cf;
	cf, r3 += squarezero + cf;
	_, squarezero += squarezero + cf;
	squarezero *= 38;
	r0 += squarezero;
	[rp + 1*8] = r1;
	[rp + 2*8] = r2;
	[rp + 3*8] = r3;
	[rp + 0*8] = r0;
	return;
}


